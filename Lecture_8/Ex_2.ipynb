{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - One-vs-all MNIST\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory (Make sure it's the root, \"Assignment 3\"):\n",
      "/Users/atakancoban/Desktop/School/2dv506 - Machine learning/Assignment 3/Lecture_8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "print(\"Current working directory (Make sure it's the root, \\\"Assignment 3\\\"):\", os.getcwd(), sep=\"\\n\")\n",
    "\n",
    "# So that changes to the a3 model are reflected here.\n",
    "import a3\n",
    "import importlib\n",
    "importlib.reload(a3)\n",
    "import a3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(clfs, test):\n",
    "    preds = []\n",
    "    for i in range(len(clfs)):\n",
    "        print(clfs[i].predict(test))\n",
    "        if clfs[i].predict(test) == 1:\n",
    "            preds.append(i)\n",
    "\n",
    "def save_pickle(file_path, data):\n",
    "    file = open(file_path, 'ab')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    file = open(file_path, 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 1 - Load & trim MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = a3.mnist()\n",
    "\n",
    "# Trim data.\n",
    "train_size = 5000\n",
    "test_size = 1000\n",
    "X_train, y_train = X_train[:train_size, :], y_train[:train_size, :]\n",
    "X_test, y_test = X_test[:test_size, :], y_test[:test_size, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 2 - Train or load SVMs for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy for each class:\n",
      "0: 99.1%\n",
      "1: 99.2%\n",
      "2: 97.7%\n",
      "3: 98.3%\n",
      "4: 97.9%\n",
      "5: 97.9%\n",
      "6: 98.5%\n",
      "7: 97.5%\n",
      "8: 97.1%\n",
      "9: 97.1%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# True to load from disk, False to train models.\n",
    "load_grids = True\n",
    "\n",
    "if load_grids:\n",
    "    grids = load_pickle('pickles/grids.pickle')\n",
    "else:\n",
    "    params = {\n",
    "        'C' : [0.1, 1, 10, 100],\n",
    "        'gamma' : [1, 0.1, 0.01, 'scale', 'auto'],\n",
    "    }\n",
    "\n",
    "    # Perform grid search.\n",
    "    grids = []\n",
    "    for col in range(y_train.shape[1]):\n",
    "        print(\"Training model for class\", col)\n",
    "        grid = GridSearchCV(SVC(), params, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train[:, col])\n",
    "        grids.append(grid)\n",
    "\n",
    "    save_pickle('pickles/grids.pickle', grids)\n",
    "\n",
    "# Print individual classifier scores.\n",
    "print(\"Cross validation accuracy for each class:\")\n",
    "for i in range(len(grids)):\n",
    "    score = round(grids[i].best_score_ * 100, 3)\n",
    "    print(f\"{i}: {score}%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 3 - Fit classifiers into OneVsAll Classifier\n",
    "### Note\n",
    "If the one-vs-all classifier predicts multiple digits but is still correct for one of them, it is considered as an\n",
    "accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating training errors for OneVsAll...\n",
      "557 errors out of 5000 predictions\n",
      "Accuracy = 88.86%\n"
     ]
    }
   ],
   "source": [
    "# Train OneVsAll classifier and predict training samples.\n",
    "clfs = [grid.best_estimator_ for grid in grids]\n",
    "ova_clf = a3.OneVsAllClassifier(clfs)\n",
    "y_pred_ova = ova_clf.predict(X_train)\n",
    "\n",
    "# Calculate error count.\n",
    "print(\"Calculating training errors for OneVsAll...\")\n",
    "y_diff_ova = y_train - y_pred_ova\n",
    "pred_count = int(y_train.shape[0])\n",
    "error_ova = np.where(y_diff_ova == 1)[0].shape[0]\n",
    "print(f\"{error_ova} errors out of {pred_count} predictions\")\n",
    "\n",
    "# Calculate accuracy.\n",
    "accuracy_ova = (pred_count - error_ova) / pred_count\n",
    "print(f\"Accuracy = {accuracy_ova*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train sklearn one-vs-one SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 errors out of 5000 predictions\n",
      "Accuracy = 99.98%\n"
     ]
    }
   ],
   "source": [
    "load_predictions = True\n",
    "\n",
    "# Reformat y from 2d to 1d to work with sklearn one-vs-one classifier.\n",
    "y_train_ovo = np.zeros(y_train.shape[0])\n",
    "for i in range(y_train.shape[0]):\n",
    "    y_train_ovo[i] = np.where(y_train[i] == 1)[0][0]\n",
    "\n",
    "# Train/load OneVsOne classifier and predict training samples.\n",
    "ovo_clf = OneVsOneClassifier(SVC(C=10, gamma=0.01)).fit(X_train, y_train_ovo)\n",
    "if load_predictions:\n",
    "    y_pred_ovo = load_pickle(\"pickles/y_preds_ovo.pickle\")\n",
    "else:\n",
    "    y_pred_ovo = ovo_clf.predict(X_train)\n",
    "    save_pickle(\"pickles/y_preds_ovo.pickle\", y_pred_ovo)\n",
    "\n",
    "# Error count.\n",
    "y_diff_ovo = (y_train_ovo != y_pred_ovo).astype(int)\n",
    "error_ovo = np.sum(y_diff_ovo)\n",
    "print(f\"{error_ovo} errors out of {pred_count} predictions\")\n",
    "\n",
    "# Calculate accuracy.\n",
    "accuracy_ovo = (pred_count - error_ovo) / pred_count\n",
    "print(f\"Accuracy = {accuracy_ovo*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}